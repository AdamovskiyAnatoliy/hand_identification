{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_path = 'DataSets/Bad50x50/27733/'\n",
    "left_path = 'DataSets/LeftHand50x50/27731/'\n",
    "rigth_path = 'DataSets/RightHand50x50/27730/'\n",
    "test_path = 'DataSets/Test189x110/27734/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_path = [bad_path, left_path, rigth_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img_path = []\n",
    "for i in dir_path :\n",
    "    image_in_dir = []\n",
    "    for j in os.listdir(i):\n",
    "        if j.split('.')[1] == 'jpg':\n",
    "            image_in_dir.append(i + j)\n",
    "    train_img_path.append(image_in_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_list = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_target = []\n",
    "for paths, target in zip(train_img_path, target_list):\n",
    "    for path in paths:\n",
    "        train_data.append(imread(path, mode='L'))\n",
    "        train_target.append(target)\n",
    "train_data = np.array(train_data)\n",
    "train_target = np.array(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img_path = []\n",
    "for i in os.listdir(test_path):\n",
    "    if i.split('.')[1] == 'jpg':\n",
    "        test_img_path.append(test_path + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for path in test_img_path:\n",
    "    test_data.append(imread(path, mode='L', ))\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size, img_rows, img_cols = 64 , 50, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(vertical_flip=True, rotation_range=45)\n",
    "datagen_train.fit(X_train.reshape(-1, 50, 50, 1))\n",
    "datagen_test = ImageDataGenerator(vertical_flip=True, rotation_range=45)\n",
    "datagen_test.fit(X_test.reshape(-1, 50, 50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 3)\n",
    "Y_test = np_utils.to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (5, 5), input_shape=input_shape, padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding ='same'),\n",
    "    Conv2D(64, (5, 5), input_shape=input_shape, padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2), strides=(2, 2), padding = 'same'),\n",
    "    Flatten(),\n",
    "    Dense(1024),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3),\n",
    "    Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "53/52 [==============================] - 75s 1s/step - loss: 0.6246 - acc: 0.6859 - val_loss: 0.3363 - val_acc: 0.8656\n",
      "Epoch 2/10\n",
      "53/52 [==============================] - 82s 2s/step - loss: 0.3086 - acc: 0.8720 - val_loss: 0.1861 - val_acc: 0.9337\n",
      "Epoch 3/10\n",
      "53/52 [==============================] - 76s 1s/step - loss: 0.1902 - acc: 0.9333 - val_loss: 0.0726 - val_acc: 0.9803\n",
      "Epoch 4/10\n",
      "53/52 [==============================] - 68s 1s/step - loss: 0.0909 - acc: 0.9682 - val_loss: 0.0371 - val_acc: 0.9875\n",
      "Epoch 5/10\n",
      "53/52 [==============================] - 70s 1s/step - loss: 0.0931 - acc: 0.9667 - val_loss: 0.0796 - val_acc: 0.9749\n",
      "Epoch 6/10\n",
      "53/52 [==============================] - 73s 1s/step - loss: 0.0452 - acc: 0.9841 - val_loss: 0.0314 - val_acc: 0.9892\n",
      "Epoch 7/10\n",
      "53/52 [==============================] - 69s 1s/step - loss: 0.0325 - acc: 0.9870 - val_loss: 0.0294 - val_acc: 0.9910\n",
      "Epoch 8/10\n",
      "53/52 [==============================] - 68s 1s/step - loss: 0.0208 - acc: 0.9917 - val_loss: 0.0181 - val_acc: 0.9946\n",
      "Epoch 9/10\n",
      "53/52 [==============================] - 69s 1s/step - loss: 0.0317 - acc: 0.9876 - val_loss: 0.0143 - val_acc: 0.9928\n",
      "Epoch 10/10\n",
      "53/52 [==============================] - 69s 1s/step - loss: 0.0197 - acc: 0.9929 - val_loss: 0.0189 - val_acc: 0.9928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25aa0c3358>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen_train.flow(X_train, Y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32,\n",
    "                    validation_data=datagen_test.flow(X_test, Y_test, batch_size=32),\n",
    "                    validation_steps = len(X_test) / 32,\n",
    "                    epochs=10, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG NUM: 0\n",
      "IMG NUM: 50\n",
      "IMG NUM: 100\n",
      "IMG NUM: 150\n",
      "IMG NUM: 200\n",
      "IMG NUM: 250\n",
      "IMG NUM: 300\n",
      "IMG NUM: 350\n",
      "IMG NUM: 400\n",
      "IMG NUM: 450\n",
      "IMG NUM: 500\n",
      "IMG NUM: 550\n",
      "IMG NUM: 600\n",
      "IMG NUM: 650\n",
      "IMG NUM: 700\n",
      "IMG NUM: 750\n",
      "IMG NUM: 800\n",
      "IMG NUM: 850\n",
      "IMG NUM: 900\n",
      "\n",
      "Total number of img: 934\n",
      "Number of left hands: 587\n",
      "Number of right hands: 429\n"
     ]
    }
   ],
   "source": [
    "mod_img = []\n",
    "value = (31, 31)\n",
    "l = 0\n",
    "left = 0\n",
    "right = 0\n",
    "for img in test_data:\n",
    "    blur = cv2.GaussianBlur(img, value, 0)\n",
    "    _, thresh1 = cv2.threshold(blur, 127, 255,\n",
    "                               cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh1, \n",
    "                                                cv2.RETR_TREE,\n",
    "                                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "    img_rect = img.copy()\n",
    "    for i in contours:\n",
    "        x, y, w, h = cv2.boundingRect(i)\n",
    "        if (x, y) == (0, 0) or w < 20 or  h < 20:\n",
    "            continue\n",
    "        crop_img = img[y:y+h, x:x+w]\n",
    "        crop_img_resize = cv2.resize(crop_img.copy(), (50,50), interpolation=cv2.INTER_AREA)\n",
    "        pred = np.round(model.predict(crop_img_resize.reshape(-1,50, 50,1)))\n",
    "        if np.all(pred == np.array([[0., 1., 0.]])):\n",
    "            img_rect = cv2.rectangle(img_rect, (x,y), (x+w,y+h),255,1) \n",
    "            img_rect = cv2.putText(img_rect.copy(), \n",
    "                                        'left', \n",
    "                                        (x, y-1),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.4,255)\n",
    "            left += 1\n",
    "        if np.all(pred == np.array([[0., 0., 1.]])):\n",
    "            img_rect = cv2.rectangle(img_rect, (x,y), (x+w,y+h),255,1)\n",
    "            img_rect = cv2.putText(img_rect.copy(), \n",
    "                                        'right', \n",
    "                                        (x,y-1),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.4,255)\n",
    "            right += 1\n",
    "    mod_img.append(img_rect)\n",
    "    if l % 50 == 0:\n",
    "        print('IMG NUM: {}'.format(l))\n",
    "    l += 1\n",
    "print('\\nTotal number of img: {}'.format(l))\n",
    "print('Number of left hands: {}'.format(left))\n",
    "print('Number of right hands: {}'.format(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dir = 'updated_img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'updated_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ed76773351df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'updated_img'"
     ]
    }
   ],
   "source": [
    "os.mkdir(name_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(name_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(mod_img)):\n",
    "    plt.imsave(str(i)+'.png', mod_img[i], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
